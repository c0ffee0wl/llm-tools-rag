"""Tests for reranker and query_analyzer modules."""

import pytest
from llm_tools_rag.query_analyzer import analyze_query, get_query_type


class TestQueryAnalyzer:
    """Tests for query analysis and weight adjustment."""

    def test_entity_query_german(self):
        """German mention queries should boost keyword search."""
        vector_weight, keyword_weight = analyze_query("ErwÃ¤hnt Willison einen Dan?")
        assert keyword_weight > vector_weight
        assert keyword_weight == 0.7
        assert vector_weight == 0.3

    def test_entity_query_english(self):
        """English mention queries should boost keyword search."""
        vector_weight, keyword_weight = analyze_query("Does the document mention Python?")
        assert keyword_weight > vector_weight

    def test_entity_query_who_is(self):
        """'Who is' queries should boost keyword search."""
        vector_weight, keyword_weight = analyze_query("Who is Dan Turkel?")
        assert keyword_weight > vector_weight

    def test_semantic_query_how(self):
        """'How' queries should boost vector search."""
        vector_weight, keyword_weight = analyze_query("How does the RAG system work?")
        assert vector_weight > keyword_weight
        assert vector_weight == 0.8
        assert keyword_weight == 0.2

    def test_semantic_query_explain(self):
        """'Explain' queries should boost vector search."""
        vector_weight, keyword_weight = analyze_query("Explain the hybrid search algorithm")
        assert vector_weight > keyword_weight

    def test_semantic_query_similar(self):
        """'Similar' queries should boost vector search."""
        vector_weight, keyword_weight = analyze_query("Find documents similar to this one")
        assert vector_weight > keyword_weight

    def test_neutral_query(self):
        """Neutral queries should use balanced weights."""
        vector_weight, keyword_weight = analyze_query("Python programming tutorial")
        assert vector_weight == keyword_weight == 0.5

    def test_get_query_type_entity(self):
        """Entity queries should return 'entity' type."""
        assert get_query_type("Does it mention John?") == "entity"

    def test_get_query_type_semantic(self):
        """Semantic queries should return 'semantic' type."""
        assert get_query_type("How does this work?") == "semantic"

    def test_get_query_type_balanced(self):
        """Neutral queries should return 'balanced' type."""
        assert get_query_type("Python code examples") == "balanced"

    def test_case_insensitive(self):
        """Query analysis should be case-insensitive."""
        v1, k1 = analyze_query("MENTION this")
        v2, k2 = analyze_query("mention this")
        assert v1 == v2 and k1 == k2


class TestRerankerModule:
    """Tests for reranker module (without loading actual model)."""

    def test_rerank_empty_documents(self):
        """Rerank should handle empty document list."""
        from llm_tools_rag.reranker import rerank

        # With empty docs, should return original ids
        result = rerank(
            query="test query",
            documents=[],
            ids=["id1", "id2"],
            model_name="ms-marco-MultiBERT-L-12"
        )
        # Empty documents returns the original ids list
        assert result == ["id1", "id2"]

    def test_rerank_mismatched_lengths(self):
        """Rerank should handle mismatched document/id lengths."""
        from llm_tools_rag.reranker import rerank

        result = rerank(
            query="test query",
            documents=["doc1"],
            ids=["id1", "id2"],  # More ids than docs
            model_name="ms-marco-MultiBERT-L-12"
        )
        # Mismatched lengths returns original ids
        assert result == ["id1", "id2"]

    def test_rerank_top_k_limit(self):
        """Rerank should respect top_k limit."""
        from llm_tools_rag.reranker import rerank

        result = rerank(
            query="test query",
            documents=[],
            ids=["id1", "id2", "id3"],
            model_name="ms-marco-MultiBERT-L-12",
            top_k=2
        )
        assert len(result) == 2


class TestConfigIntegration:
    """Tests for reranker/query_analyzer config integration."""

    def test_config_defaults(self):
        """Config should have correct defaults for new features."""
        from llm_tools_rag.config import DEFAULT_CONFIG

        assert DEFAULT_CONFIG["reranker_model"] == "ms-marco-MultiBERT-L-12"
        assert DEFAULT_CONFIG["reranker_top_k"] is None
        assert DEFAULT_CONFIG["query_aware_weights"] is True
        assert DEFAULT_CONFIG["contextual_headers"] is True

    def test_config_validation_reranker_model(self):
        """Config should validate reranker_model type."""
        from llm_tools_rag.config import RAGConfig, deep_merge, DEFAULT_CONFIG
        import tempfile
        import yaml
        import os

        # Create a temp config with invalid reranker_model
        with tempfile.TemporaryDirectory() as tmpdir:
            config_file = os.path.join(tmpdir, "config.yaml")
            with open(config_file, 'w') as f:
                yaml.dump({"reranker_model": 123}, f)  # Invalid type

            # Create a mock RAGConfig that uses the temp file
            # We can't easily test this without mocking, so just verify the validation logic
            config = deep_merge(DEFAULT_CONFIG, {"reranker_model": None})
            assert config["reranker_model"] is None  # None is valid

            config = deep_merge(DEFAULT_CONFIG, {"reranker_model": "custom-model"})
            assert config["reranker_model"] == "custom-model"  # String is valid
